{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3328,
     "status": "ok",
     "timestamp": 1604068024292,
     "user": {
      "displayName": "August DuMont Schütte",
      "photoUrl": "",
      "userId": "15031524827232593617"
     },
     "user_tz": -60
    },
    "id": "knPt0_kMn96U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tvis\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3312,
     "status": "ok",
     "timestamp": 1604068024295,
     "user": {
      "displayName": "August DuMont Schütte",
      "photoUrl": "",
      "userId": "15031524827232593617"
     },
     "user_tz": -60
    },
    "id": "W5oKa4kroIGI",
    "outputId": "52df3f43-11f1-4833-ef69-8085de374089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1604065834892,
     "user": {
      "displayName": "August DuMont Schütte",
      "photoUrl": "",
      "userId": "15031524827232593617"
     },
     "user_tz": -60
    },
    "id": "2hYNBzPTt6ZB"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./gdrive/My Drive/coding_projects/transformer/wmt14\"\n",
    "#torchtext.datasets.WMT14.download(data_dir)\n",
    "#!python3 -m spacy download de\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1604065834893,
     "user": {
      "displayName": "August DuMont Schütte",
      "photoUrl": "",
      "userId": "15031524827232593617"
     },
     "user_tz": -60
    },
    "id": "YJAbtjN3oInT"
   },
   "outputs": [],
   "source": [
    "def get_loader(data_dir,\n",
    "               batch_size,\n",
    "               random_seed,\n",
    "               valid_size=0.2,\n",
    "               shuffle=True,\n",
    "               num_workers=2):\n",
    "\n",
    "\n",
    "    from torchtext import data\n",
    "    from torchtext import datasets\n",
    "    from torchtext.datasets import TranslationDataset\n",
    "    import re\n",
    "    import spacy\n",
    "\n",
    "    spacy_de = spacy.load('de')\n",
    "    spacy_en = spacy.load('en')\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    BLANK_WORD = \"<blank>\"\n",
    "    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
    "    TGT = data.Field(tokenize=tokenize_en, init_token=BOS_WORD, eos_token=EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "    MAX_LEN = 100\n",
    "    print('splits')\n",
    "    train, val, test = datasets.WMT14.splits(\n",
    "                                  exts=('.de', '.en'),\n",
    "                                  train='train.tok.clean.bpe.32000', \n",
    "                                  validation='newstest2013.tok.bpe.32000', \n",
    "                                  test='newstest2014.tok.bpe.32000',\n",
    "                                  fields=(SRC, TGT),\n",
    "                                  filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN,\n",
    "                                  root=data_dir)\n",
    "\n",
    "    print(train.fields)\n",
    "    print(len(train))\n",
    "    print(vars(train[0]))\n",
    "    print(vars(train[100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1604072807837,
     "user": {
      "displayName": "August DuMont Schütte",
      "photoUrl": "",
      "userId": "15031524827232593617"
     },
     "user_tz": -60
    },
    "id": "ZqhXyeD1yUNO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"Attention layer.\n",
    "\"\"\"\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, h=4, d_model=128, d_k=32, d_v=32):\n",
    "        super(Attention, self).__init__()\n",
    "        self.h = h\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        self.W_q = torch.rand(size=(h, d_model, d_k),requires_grad=True)\n",
    "        self.W_k = torch.rand(size=(h, d_model, d_k),requires_grad=True)\n",
    "        self.W_v = torch.rand(size=(h, d_model, d_v),requires_grad=True)\n",
    "        self.W_o = torch.rand(size=(int(h*d_v),d_model),requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x in [BS,seq_len,d_model]\n",
    "        Q = torch.einsum('ijk,lkm->ijlm', x, self.W_q) #[BS,seq_len,h,d_k]\n",
    "        K = torch.einsum('ijk,lkm->ijlm', x, self.W_k) #[BS,seq_len,h,d_k]\n",
    "        V = torch.einsum('ijk,lkm->ijlm', x, self.W_v) #[BS,seq_len,h,d_v]\n",
    "        QK_T = torch.einsum('ijkl,ijkl->ijk',Q,K)                    #[BS,seq_len,h]\n",
    "        att  = torch.einsum('ijk,ijkl->ijkl', F.softmax(QK_T),V) #[BS,seq_len,h,d_v]\n",
    "        att_conc = att.view(att.shape[0],att.shape[1],-1)            #[BS,seq_len,h*d_v]\n",
    "        mh_att = torch.einsum('ijk,kl->ijl',att_conc,self.W_o)       #[BS,seq_len,d_model]\n",
    "\n",
    "        return mh_att\n",
    "\n",
    "x = torch.rand(size=(24,10,128))\n",
    "mod = Attention()\n",
    "out = mod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIscyljPMPCW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPR82KJn8rj29u4WgdT9/Kl",
   "collapsed_sections": [],
   "name": "transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
